1. (obrigatório) Verificação numérica do gradiente; a fazer
2. (obrigatório) Interface de linha de comando para teste do backpropagation; pablo
6. (obrigatório) Testes (para cada dataset) com diferentes arquiteturas de rede; a fazer (perguntar ao professor as metricas)
7. (obrigatório) Testes (para cada dataset) com diferentes meta-parâmetros: taxa de
aprendizado, taxa de regularização, etc; a fazer (perguntar ao professor as metricas)
8. (obrigatório) Curvas de aprendizado mostrando a função de custo J para cada dataset;
9. (obrigatório) Análise dos datasets 1-4; a fazer
14. (opcional) Suporte a treinamento mini-batch; a fazer
16. (opcional) Suporte ao método do momento a fazer

Porque o log do J não fucniona com Relu e tanhH

Normalizar o Ionoshpere, visto que ela já tem uma normalização entre -1 e 1

Nossa normalização é entre 0 e 1, precisa renormalizar?